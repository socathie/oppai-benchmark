{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://blog.keras.io/building-autoencoders-in-tf.keras.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = tf.keras.Input(shape=(28, 28, 1), name='input_img')\n",
    "\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = tf.keras.layers.MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "# at this point the representation is (4, 4, 8) i.e. 128-dimensional\n",
    "\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = tf.keras.Model(input_img, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build decoder\n",
    "\n",
    "encoded_input = tf.keras.Input(shape=(4, 4, 8), name='encoded_input')\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(encoded_input)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(8, (3, 3), activation='relu', padding='same')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "x = tf.keras.layers.Conv2D(16, (3, 3), activation='relu')(x)\n",
    "x = tf.keras.layers.UpSampling2D((2, 2))(x)\n",
    "decoded = tf.keras.layers.Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "decoder = tf.keras.Model(encoded_input, decoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# plot model and display image\n",
    "plot_model(decoder, to_file='decoder.png')\n",
    "plot_model(autoencoder, to_file='autoencoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iterate over the layers and export models from first to current layer to h5 files\n",
    "for i in range(1, len(autoencoder.layers)):\n",
    "    model_i = tf.keras.Model(inputs=autoencoder.inputs, outputs=autoencoder.layers[i].output, name=f\"autoencoder_{i}\")\n",
    "    model_i.save(f\"autoencoder_{i}/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(decoder.layers)):\n",
    "    model_i = tf.keras.Model(inputs=decoder.inputs, outputs=decoder.layers[i].output, name=f\"decoder_{i}\")\n",
    "    model_i.save(f\"decoder_{i}/model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tf2onnx\n",
    "\n",
    "spec = tf.TensorSpec([1, 28, 28, 1], tf.float32, name='input_img')\n",
    "\n",
    "for i in range(1, len(autoencoder.layers)):\n",
    "    model_i = tf.keras.models.load_model(f'autoencoder_{i}/model.h5')\n",
    "    tf2onnx.convert.from_keras(\n",
    "        model_i,\n",
    "        input_signature=[spec],\n",
    "        inputs_as_nchw=['input_img'],\n",
    "        opset=12,\n",
    "        output_path=f'autoencoder_{i}/model.onnx'\n",
    "    )\n",
    "    tf2onnx.convert.from_keras(\n",
    "        model_i,\n",
    "        input_signature=[spec],\n",
    "        # inputs_as_nchw=['input_img'],\n",
    "        opset=18,\n",
    "        output_path=f'autoencoder_{i}/opset18.onnx'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = tf.TensorSpec([1, 4, 4, 8], tf.float32, name='encoded_input')\n",
    "\n",
    "for i in range(1, len(decoder.layers)):\n",
    "    model_i = tf.keras.models.load_model(f'decoder_{i}/model.h5')\n",
    "    tf2onnx.convert.from_keras(\n",
    "        model_i,\n",
    "        input_signature=[spec],\n",
    "        inputs_as_nchw=['encoded_input'],\n",
    "        opset=12,\n",
    "        output_path=f'decoder_{i}/model.onnx'\n",
    "    )\n",
    "    tf2onnx.convert.from_keras(\n",
    "        model_i,\n",
    "        input_signature=[spec],\n",
    "        # inputs_as_nchw=['encoded_input'],\n",
    "        opset=18,\n",
    "        output_path=f'decoder_{i}/opset18.onnx'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ref: https://github.com/zkonduit/ezkl/blob/bceac2fab530fd01701aec3d8018ce318f6c42e1/examples/notebooks/mnist_vae.ipynb\n",
    "!RUST_LOG=trace\n",
    "\n",
    "# import os\n",
    "import ezkl\n",
    "import json\n",
    "\n",
    "\n",
    "for i in range(1, len(autoencoder.layers)):\n",
    "    print(f'autoencoder_{i}/model.onnx')\n",
    "    model_path = os.path.join(f'autoencoder_{i}/model.onnx')\n",
    "    settings_path = os.path.join(f'autoencoder_{i}/settings.json')\n",
    "\n",
    "    res = ezkl.gen_settings(model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # read the settings from json\n",
    "    with open(settings_path, 'r') as f:\n",
    "        settings = json.load(f)\n",
    "    \n",
    "    # print the \"num_rows\" from the settings\n",
    "    print(settings['num_rows'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(decoder.layers)):\n",
    "    model_path = os.path.join(f'decoder_{i}/model.onnx')\n",
    "    settings_path = os.path.join(f'decoder_{i}/settings.json')\n",
    "\n",
    "    res = ezkl.gen_settings(model_path, settings_path)\n",
    "    assert res == True\n",
    "\n",
    "    # read the settings from json\n",
    "    with open(settings_path, 'r') as f:\n",
    "        settings = json.load(f)\n",
    "    \n",
    "    # print the \"num_rows\" from the settings\n",
    "    print(settings['num_rows'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from keras2circom.keras2circom import circom, transpiler\n",
    "circom.dir_parse('../keras2circom/node_modules/circomlib-ml/circuits/', skips=['util.circom', 'circomlib-matrix', 'circomlib', 'crypto'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(autoencoder.layers)):\n",
    "    args = {\n",
    "        '<model.h5>': f'autoencoder_{i}/model.h5',\n",
    "        '--output': f'autoencoder_{i}',\n",
    "        '--raw': False,\n",
    "        '--decimals': \"18\"\n",
    "    }\n",
    "    transpiler.transpile(args['<model.h5>'], args['--output'], args['--raw'], args['--decimals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1, len(decoder.layers)):\n",
    "    args = {\n",
    "        '<model.h5>': f'decoder_{i}/model.h5',\n",
    "        '--output': f'decoder_{i}',\n",
    "        '--raw': False,\n",
    "        '--decimals': \"18\"\n",
    "    }\n",
    "    transpiler.transpile(args['<model.h5>'], args['--output'], args['--raw'], args['--decimals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras2circom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
